{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://towardsdatascience.com/sentiment-analysis-with-python-part-2-4f71e7bde59a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# Prevent future/deprecation warnings from showing in output\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train = []\n",
    "for line in open('movie_data/full_train.txt', encoding=\"utf8\"):\n",
    "    \n",
    "    reviews_train.append(line.strip())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'Brilliant over-acting by Lesley Ann Warren. Best dramatic hobo lady I have ever seen, and love scenes in clothes warehouse are second to none. The corn on face is a classic, as good as anything in Blazing Saddles. The take on lawyers is also superb. After being accused of being a turncoat, selling out his boss, and being dishonest the lawyer of Pepto Bolt shrugs indifferently \"I\\'m a lawyer\" he says. Three funny words. Jeffrey Tambor, a favorite from the later Larry Sanders show, is fantastic here too as a mad millionaire who wants to crush the ghetto. His character is more malevolent than usual. The hospital scene, and the scene where the homeless invade a demolition site, are all-time classics. Look for the legs scene and the two big diggers fighting (one bleeds). This movie gets better each time I see it (which is quite often).'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "\"This is one of the dumbest films, I've ever seen. It rips off nearly ever type of thriller and manages to make a mess of them all.<br /><br />There's not a single good line or character in the whole mess. If there was a plot, it was an afterthought and as far as acting goes, there's nothing good to say so Ill say nothing. I honestly cant understand how this type of nonsense gets produced and actually released, does somebody somewhere not at some stage think, 'Oh my god this really is a load of shite' and call it a day. Its crap like this that has people downloading illegally, the trailer looks like a completely different film, at least if you have download it, you haven't wasted your time or money Don't waste your time, this is painful.\""
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train [24999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test = []\n",
    "for line in open('movie_data/full_test.txt', encoding=\"utf8\"):\n",
    "    \n",
    "    reviews_test.append(line.strip())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because of special structure of data\n",
    "#Don't use this at home!!!!!\n",
    "#Both train and test have  25000 observations\n",
    "#Both train and test can be split in : First 12500 positive , last 12500 negative\n",
    "#Don't do this at home\n",
    "\n",
    "target = [1 if i < 12500 else 0 for i in range(25000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    \n",
    "    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "reviews_test_clean = preprocess_reviews(reviews_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_vectorizer = CountVectorizer(binary=False)\n",
    "#baseline_vectorizer.fit(reviews_train_clean)\n",
    "X_baseline = baseline_vectorizer.fit_transform(reviews_train_clean)\n",
    "\n",
    "# Not the difference between fit_transform and transform\n",
    "X_test_baseline = baseline_vectorizer.transform(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(baseline_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (reviews_train_clean[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#review0_baseline = baseline_vectorizer.transform([reviews_train_clean[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (review0_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Shape of Sparse Matrix: ',X_baseline.shape)\n",
    "print ('Amount of Non-Zero occurences: ', X_baseline.nnz)\n",
    "print ('sparsity: %s' % (1- 100.0 * X_baseline.nnz /\n",
    "                             (X_baseline.shape[0] *X_baseline.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = LogisticRegression()\n",
    "final_model.fit(X_baseline, target)\n",
    "print (\"Baseline Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test_baseline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Baseline AUC: %s\" %  roc_auc_score(target, final_model.predict_proba(X_test_baseline)[::,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "english_stop_words = stopwords.words('english')\n",
    "def remove_stop_words(corpus):\n",
    "    removed_stop_words = []\n",
    "    for review in corpus:\n",
    "        removed_stop_words.append(\n",
    "            ' '.join([word for word in review.split() \n",
    "                      if word not in english_stop_words])\n",
    "        )\n",
    "    return removed_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stop_words_train = remove_stop_words(reviews_train_clean)\n",
    "no_stop_words_test = remove_stop_words(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(binary=True)\n",
    "X = cv.fit_transform(no_stop_words_train)\n",
    "X_test = cv.transform(no_stop_words_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X, target)\n",
    "print (\"Remove Stopwords Accuracy : %s\"  % ( accuracy_score(target, lr.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Remove Stopwords AUC: %s\" %  roc_auc_score(target, lr.predict_proba(X_test)[::,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skip during demo\n",
    "def get_stemmed_text(corpus):\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes 5 minutes\n",
    "#Skip during demo\n",
    "stemmed_reviews_train = get_stemmed_text(reviews_train_clean)\n",
    "stemmed_reviews_test = get_stemmed_text(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skip during demo\n",
    "with open(\"stemmed_reviews_train.txt\", \"wb\") as fp: \n",
    "      pickle.dump(stemmed_reviews_train, fp)\n",
    "with open(\"stemmed_reviews_test.txt\", \"wb\") as fp: \n",
    "      pickle.dump(stemmed_reviews_test, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stemmed_reviews_train.txt\", \"rb\") as fp:   # Unpickling\n",
    "      stemmed_reviews_train_loaded = pickle.load(fp)\n",
    "with open(\"stemmed_reviews_test.txt\", \"rb\") as fp:   # Unpickling\n",
    "      stemmed_reviews_test_loaded = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(binary=True)\n",
    "\n",
    "X = cv.fit_transform(stemmed_reviews_train_loaded)\n",
    "X_test = cv.transform(stemmed_reviews_test_loaded)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stemmed = LogisticRegression()\n",
    "final_stemmed.fit(X, target)\n",
    "print (\"Stemmed Accuracy: %s\" % accuracy_score(target, final_stemmed.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Stemming AUC: %s\" %  roc_auc_score(target, final_stemmed.predict_proba(X_test)[::,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(final_stemmed, 'final_stemmed.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stemmed_loaded= load('final_stemmed.joblib')\n",
    "print (\"Final Stemming: %s\" % accuracy_score(target, final_stemmed_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemmatized_text(corpus):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes 5 minutes\n",
    "#Skip during demo\n",
    "lemmatized_reviews_train = get_lemmatized_text(reviews_train_clean)\n",
    "lemmatized_reviews_test = get_lemmatized_text(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skip during demo\n",
    "with open(\"lemmatized_reviews_train.txt\", \"wb\") as fp: \n",
    "      pickle.dump(lemmatized_reviews_train, fp)\n",
    "with open(\"lemmatized_reviews_test.txt\", \"wb\") as fp: \n",
    "      pickle.dump(lemmatized_reviews_test, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stemmed_reviews_train.txt\", \"rb\") as fp:   # Unpickling\n",
    "      stemmed_reviews_train_loaded = pickle.load(fp)\n",
    "with open(\"stemmed_reviews_test.txt\", \"rb\") as fp:   # Unpickling\n",
    "      stemmed_reviews_test_loaded = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(binary=True)\n",
    "\n",
    "X = cv.fit_transform(lemmatized_reviews_train)\n",
    "X_test = cv.transform(lemmatized_reviews_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lemmatized = LogisticRegression()\n",
    "final_lemmatized.fit(X, target)\n",
    "print (\"Final Lemmatized Accuracy: %s\"  % accuracy_score(target, final_lemmatized.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Lemmatized AUC: %s\" %  roc_auc_score(target, final_lemmatized.predict_proba(X_test)[::,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_test = ngram_vectorizer.transform(reviews_test_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "final_ngram = LogisticRegression()\n",
    "final_ngram.fit(X, target)\n",
    "print (\"Accuracy uni- bi grams: %s\"  % accuracy_score(target, final_ngram.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Uni- bi grams AUC: %s\" %  roc_auc_score(target, final_ngram.predict_proba(X_test)[::,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wc_vectorizer = CountVectorizer(binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wc_vectorizer.fit_transform(reviews_train_clean)\n",
    "X_test = wc_vectorizer.transform(reviews_test_clean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_wc = LogisticRegression()\n",
    "final_wc.fit(X, target)\n",
    "print (\"WordCount Accuracy: %s\"  % accuracy_score(target, final_wc.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"WordCount AUC: %s\" %  roc_auc_score(target, final_wc.predict_proba(X_test)[::,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf_vectorizer.fit_transform(reviews_train_clean)\n",
    "X_test = tfidf_vectorizer.transform(reviews_test_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tfidf = LogisticRegression()\n",
    "final_tfidf.fit(X, target)\n",
    "print (\"TF_IDF Accuracy: %s\" % accuracy_score(target, final_tfidf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"TF_IDF AUC: %s\" %  roc_auc_score(target, final_tfidf.predict_proba(X_test)[::,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ngram_vectorizer.fit_transform(reviews_train_clean)\n",
    "X_test = ngram_vectorizer.transform(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_svm_ngram = LinearSVC()\n",
    "final_svm_ngram.fit(X, target)\n",
    "print (\"SVC Accuracy: %s\"  % accuracy_score(target, final_svm_ngram.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['in', 'of', 'at', 'a', 'the']\n",
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words=stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ngram_vectorizer.fit_transform(reviews_train_clean)\n",
    "X_test = ngram_vectorizer.transform(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = LinearSVC()\n",
    "final.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" % accuracy_score(target, final.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Positive and Negative Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        ngram_vectorizer.get_feature_names(), final.coef_[0]\n",
    "    )\n",
    "}\n",
    "\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:10]:\n",
    "    print (best_positive)\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:10]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}