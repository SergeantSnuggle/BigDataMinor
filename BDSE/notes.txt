1)webscrapping zo'n 10 a 20 reviews( genoeg om te checken of je algoritme werkt)
2)Dataframe that contains reviews and labels in 2 colloms. Labels means if it is positive of negative(lambda functie)
3)Hand written reviews
Dit is voor assignment 1 Afmaken in vakantie

make decisiontreeclassifier better with parameters https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html

Homework:
Werk aan opdracht 1:
-Webscraping(save data in DB)
-query(stored procedures) - get data from db strore in dataframe
-clean your data(emoji weghalen, etc)

pre processing data:

Stemming data -> Worden die het zelfde zijn verwijderen, dus Play, Plays, Played, Playing, veranderen naar play
Lemmatization -> Synomymen e.q. football & soccer

Lowercase: Me & me veranderen naar alleen me
Removing numbers. Maar je wilt bijvoorbeeld jaargetallen wel bewaren als je daar mee bezig bent
Removing punctuations Afkortingen zoals W.A.S.P wordt veraderd naar wasp, moet je dus exceptions making of je wilt het niet verwijderen.
Misschien alleen verwijderen als er een spatie acter staat

Noise removal:
Remove text file headers and footers
Remove HTML, XML, metadata etc

Corpus -> large collection of texts voor NLP. Dus alle reviews bij elkaar is een corpus

Voor countcvectorizer
#fit_transform all the new words are accounted for -> TRAIN set
#transform only the words already met (in the TRAIN) are accounted for -> TEST set
Je doet dit pas na het opslitsen van je data

Je moet ook de reviews van de leraren preprocessen. Dus maakt een functie die de data preprocessed

Uit database clean data halen, dus alleen een bepaalde collumen eruit halen met de select. Of je kan alleen uniques toepassen.
De sql querry moet wat uitgebreider zijn

Voeg alle data toe in 1 dataframe. En stop dat in een database

Of je kan kaggle gebruiken voor trainen. Dan de andere data(Eigen data en scrapped data) gebruiken om te testen

Ik doe scrapped data en eigen reviews in een database

Plots ideeën:   Hoeveel per hotel
                Hoeveel negatief en positief
                Kijk nog meer naar de data voor ideeën

(Hoef niet te gebruiken voor scrapped data en eigen data) omdat je alleen text en score scrapped

4 april deadline van het rapport

Kijk een naar TFIDF, SQL procedures

Je kan kijken in je verslag naar het verschil TFIDF tussen fit_transform etc

Je kan ook de data splitten in 2 dataframes eentje positief en eentje negatief en dan op elk een test train split doen
Daarna kan je ze samenvoegen
Je kan ook balanceren, dat je maar 10k per doet(10k positief en 10k negatief) en dan 2k test data

Run randomtree met meerdere maxdepths(increment met 1, begin met 5 en stop bij 50) en print de resultaten in een plot voor het verslag
Doe dan accuracy AUC en Con Mat en dan vergelijken met tijd. Hoe lang het duurde. Stop die resultaten in een dataframe
Kijk naar elbows in graph

Silhoutte score zo hoog mogelijk

TfIdf cijfer -> hoe hoger hoe vaker gebruikt.
Gebruik ook dat countvectorizer met 2 woorden ding

Kijkt het verschil tussen de resultaten van TfIdf en countvectorizer

Ook nog even pickletjes gebruiken als mijn models compleet zijn, hoef ik het niet elke keer te runnen

Screenshot van je sql querries in je verslag
Verwijzingen er ook in, waar je informatie vandaan hebt
Code snippets er ook in

additional stopwords met en zonder ook in verslag, het verschil in wordcloud

Dinsdag: data cleaning + model training
Chrome niet in admin uitvoeren anders krijg je error met chromedriver

sources: https://stackoverflow.com/questions/54608088/what-is-gridsearch-cv-results-could-any-explain-all-the-things-in-that-i-e-me

SELECT * FROM label_kaggle_reviews where label = 0 ORDER BY negative_word_count DESC, positive_word_count ASC LIMIT 10000;

SELECT * FROM label_kaggle_reviews where label = 1 ORDER BY negative_word_count ASC, positive_word_count DESC LIMIT 10000